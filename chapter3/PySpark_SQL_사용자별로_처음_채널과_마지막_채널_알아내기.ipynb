{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "b9509ff1-271c-4487-aee1-048eceb771d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.3.1 in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.3.1 py4j==0.10.9.5 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdTTZZqVA0Xa",
        "outputId": "ffb3d1c5-4535-48f8-d9ab-2ec70a468414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-23 23:03:42--  https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.20.1043/RedshiftJDBC42-no-awssdk-1.2.20.1043.jar\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.1.46, 52.216.92.229, 54.231.164.168, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.1.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2413910 (2.3M) [application/java-archive]\n",
            "Saving to: ‘RedshiftJDBC42-no-awssdk-1.2.20.1043.jar.1’\n",
            "\n",
            "RedshiftJDBC42-no-a 100%[===================>]   2.30M  11.5MB/s    in 0.2s    \n",
            "\n",
            "2023-01-23 23:03:42 (11.5 MB/s) - ‘RedshiftJDBC42-no-awssdk-1.2.20.1043.jar.1’ saved [2413910/2413910]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /usr/local/lib/python3.8/dist-packages/pyspark/jars && wget https://s3.amazonaws.com/redshift-downloads/drivers/jdbc/1.2.20.1043/RedshiftJDBC42-no-awssdk-1.2.20.1043.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "your 131072x1 screen size is bogus. expect trouble\n",
            "24/06/22 00:33:49 WARN Utils: Your hostname, LAPTOP-8CK94L0D resolves to a loopback address: 127.0.1.1; using 172.21.9.191 instead (on interface eth0)\n",
            "24/06/22 00:33:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "24/06/22 00:33:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL #1\") \\\n",
        "    .config(\"spark.jars\", \"/home/sangwon/.local/lib/python3.10/site-packages/pyspark/jars/redshift-jdbc42-2.1.0.14.jar\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BX91cDdZj3AK"
      },
      "outputs": [],
      "source": [
        "rows_test = [\n",
        "    { 'value': 1, 'name': 'Luka' },\n",
        "    { 'value': 2, 'name': 'Luka'},\n",
        "    { 'value': 3, 'name': 'Dirk' },\n",
        "    { 'value': 4, 'name': 'Dirk' },\n",
        "    { 'value': 5, 'name': 'Luka' },\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(rows_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XRkbATLkfkt",
        "outputId": "01a6741e-3ee6-4e54-bb98-33491b1f87d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- value: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMvZ11_71j9F",
        "outputId": "735f1c17-619b-4d2f-de41-0f569f6eccb3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+\n",
            "|name|value|\n",
            "+----+-----+\n",
            "|Luka|    1|\n",
            "|Luka|    2|\n",
            "|Dirk|    3|\n",
            "|Dirk|    4|\n",
            "|Luka|    5|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S0ZGpnfhk1kP"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"rows_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OGdFV7MlCZf",
        "outputId": "baaa208d-7c5a-4005-d2f2-946bb6654fa6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/06/22 00:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+\n",
            "|value|rolling_sum|\n",
            "+-----+-----------+\n",
            "|    1|          6|\n",
            "|    2|         10|\n",
            "|    3|         15|\n",
            "|    4|         14|\n",
            "|    5|         12|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT \n",
        "    value,\n",
        "    SUM(value) OVER (\n",
        "        order by value \n",
        "        rows between 2 preceding and 2 following\n",
        "    ) AS rolling_sum\n",
        "  FROM rows_test\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ffkge4xmrMr",
        "outputId": "13360eff-d1dd-4b02-9ec8-6ac0bb51536f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/06/22 00:34:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
            "24/06/22 00:34:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+\n",
            "|value|rolling_sum|\n",
            "+-----+-----------+\n",
            "|    1|          6|\n",
            "|    2|         10|\n",
            "|    3|         15|\n",
            "|    4|         15|\n",
            "|    5|         15|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT \n",
        "    value,\n",
        "    SUM(value) OVER (\n",
        "        order by value \n",
        "        rows between unbounded preceding and 2 following\n",
        "    ) AS rolling_sum\n",
        "  FROM rows_test\"\"\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpmrVV4T107A",
        "outputId": "56266aec-e46d-47c7-b938-71e7e171aefb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 9:============================================>              (6 + 2) / 8]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+---------+---------+\n",
            "|name|value|min_value|max_value|\n",
            "+----+-----+---------+---------+\n",
            "|Dirk|    3|        3|        4|\n",
            "|Dirk|    4|        3|        4|\n",
            "|Luka|    1|        1|        5|\n",
            "|Luka|    2|        1|        5|\n",
            "|Luka|    5|        1|        5|\n",
            "+----+-----+---------+---------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT \n",
        "    *,\n",
        "    FIRST_VALUE(value) OVER (\n",
        "        partition by name\n",
        "        order by value \n",
        "        rows between unbounded preceding and unbounded following\n",
        "    ) AS min_value,\n",
        "    LAST_VALUE(value) OVER (\n",
        "        partition by name\n",
        "        order by value \n",
        "        rows between unbounded preceding and unbounded following\n",
        "    ) AS max_value    \n",
        "  FROM rows_test\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElawwmWzcylW"
      },
      "source": [
        "## Redshift 상의 다음 테이블을 데이터프레임으로 로딩하기\n",
        "user_session_channel, session_timestamp, session_transaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EEaNuN3xKNXm"
      },
      "outputs": [],
      "source": [
        "# Redshift와 연결해서 DataFrame으로 로딩하기\n",
        "url = \"jdbc:redshift://learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com:5439/dev?user=guest&password=Guest1234\"\n",
        "\n",
        "df_user_session_channel = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.user_session_channel\") \\\n",
        "    .load()\n",
        "\n",
        "df_session_timestamp = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.session_timestamp\") \\\n",
        "    .load()\n",
        "\n",
        "df_session_transaction = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"driver\", \"com.amazon.redshift.jdbc42.Driver\") \\\n",
        "    .option(\"url\", url) \\\n",
        "    .option(\"dbtable\", \"raw_data.session_transaction\") \\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AjcT5LWi7_B5"
      },
      "outputs": [],
      "source": [
        "df_user_session_channel.createOrReplaceTempView(\"user_session_channel\")\n",
        "df_session_timestamp.createOrReplaceTempView(\"session_timestamp\")\n",
        "df_session_transaction.createOrReplaceTempView(\"session_transaction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3UxHdoLC5Bt",
        "outputId": "85e24cdb-fee6-4889-9056-4347a2776d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------+---------+\n",
            "|userid|           sessionid|  channel|\n",
            "+------+--------------------+---------+\n",
            "|  1651|0004289ee1c7b8b08...|  Organic|\n",
            "|  1197|00053f5e11d1fe4e4...| Facebook|\n",
            "|  1401|00056c20eb5a02958...| Facebook|\n",
            "|  1399|00063cb5da1826feb...| Facebook|\n",
            "|  1667|000958fdaefe0dd06...|Instagram|\n",
            "+------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_user_session_channel.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9lIcukADIgk",
        "outputId": "de7a4728-32f5-412a-a053-4dd702642b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|           sessionid|                  ts|\n",
            "+--------------------+--------------------+\n",
            "|0002ac0d783338cfe...|2019-07-29 12:39:...|\n",
            "|00053f5e11d1fe4e4...|2019-06-24 13:04:...|\n",
            "|00056c20eb5a02958...| 2019-09-26 14:50:17|\n",
            "|00063cb5da1826feb...|2019-10-16 14:04:...|\n",
            "|0007cda84fafdcf42...|2019-05-22 08:02:...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_session_timestamp.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwiwGeXRDNk2",
        "outputId": "af76c473-4949-4f1f-98fe-412b5f35177a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------+------+\n",
            "|           sessionid|refunded|amount|\n",
            "+--------------------+--------+------+\n",
            "|00029153d12ae1c9a...|   false|    85|\n",
            "|008909bd27b680698...|   false|    13|\n",
            "|0107acb41ef20db22...|   false|    16|\n",
            "|018544a2c48077d2c...|   false|    39|\n",
            "|020c38173caff0203...|   false|    61|\n",
            "+--------------------+--------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_session_transaction.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpjU9yXVJAph"
      },
      "source": [
        "## 위의 테이블들을 이용해서 사용자별로 처음 채널과 마지막 채널 알아내기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F8DVGlKRQkrD"
      },
      "outputs": [],
      "source": [
        "first_last_channel_df = spark.sql(\"\"\"\n",
        "WITH RECORD AS (\n",
        "  SELECT /*사용자의 유입에 따른, 채널 순서 매기는 쿼리*/\n",
        "      userid,\n",
        "      channel, \n",
        "      ROW_NUMBER() OVER (PARTITION BY userid ORDER BY ts ASC) AS seq_first,\n",
        "      ROW_NUMBER() OVER (PARTITION BY userid ORDER BY ts DESC) AS seq_last\n",
        "  FROM user_session_channel u\n",
        "  LEFT JOIN session_timestamp t\n",
        "    ON u.sessionid = t.sessionid\n",
        ")\n",
        "SELECT /*유저의 첫번째 유입채널, 마지막 유입 채널 구하기*/\n",
        "      f.userid,\n",
        "      f.channel first_channel,\n",
        "      l.channel last_channel\n",
        "FROM RECORD f\n",
        "INNER JOIN RECORD l ON f.userid = l.userid\n",
        "WHERE f.seq_first = 1 and l.seq_last = 1\n",
        "ORDER BY userid\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4qr9Qw4RaJ8",
        "outputId": "97fa8fb6-da19-4667-b40b-5acbe334e7dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------+------------+\n",
            "|userid|first_channel|last_channel|\n",
            "+------+-------------+------------+\n",
            "|    27|      Youtube|   Instagram|\n",
            "|    29|        Naver|       Naver|\n",
            "|    33|       Google|     Youtube|\n",
            "|    34|      Youtube|       Naver|\n",
            "|    36|        Naver|     Youtube|\n",
            "|    40|      Youtube|      Google|\n",
            "|    41|     Facebook|     Youtube|\n",
            "|    44|        Naver|   Instagram|\n",
            "|    45|      Youtube|   Instagram|\n",
            "|    59|    Instagram|   Instagram|\n",
            "+------+-------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "first_last_channel_df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rvBR0KhAc5J1"
      },
      "outputs": [],
      "source": [
        "first_last_channel_df2 = spark.sql(\"\"\"\n",
        "SELECT DISTINCT A.userid,\n",
        "    FIRST_VALUE(A.channel) over(partition by A.userid order by B.ts\n",
        "rows between unbounded preceding and unbounded following) AS First_Channel,\n",
        "    LAST_VALUE(A.channel) over(partition by A.userid order by B.ts\n",
        "rows between unbounded preceding and unbounded following) AS Last_Channel\n",
        "FROM user_session_channel A\n",
        "LEFT JOIN session_timestamp B\n",
        "ON A.sessionid = B.sessionid\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWvT_Sbp2dNY",
        "outputId": "67eafa90-448c-4b13-f490-78473f5935f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 36:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------------+------------+\n",
            "|userid|First_Channel|Last_Channel|\n",
            "+------+-------------+------------+\n",
            "|    27|      Youtube|   Instagram|\n",
            "|    29|        Naver|       Naver|\n",
            "|    33|       Google|     Youtube|\n",
            "|    34|      Youtube|       Naver|\n",
            "|    36|        Naver|     Youtube|\n",
            "|    40|      Youtube|      Google|\n",
            "|    41|     Facebook|     Youtube|\n",
            "|    44|        Naver|   Instagram|\n",
            "|    45|      Youtube|   Instagram|\n",
            "|    59|    Instagram|   Instagram|\n",
            "|    64|      Youtube|     Youtube|\n",
            "|    65|      Youtube|     Organic|\n",
            "|    68|      Youtube|     Organic|\n",
            "|    69|     Facebook|   Instagram|\n",
            "|    80|      Organic|       Naver|\n",
            "|    84|       Google|     Youtube|\n",
            "|    87|      Youtube|      Google|\n",
            "|    97|      Organic|     Organic|\n",
            "|   112|     Facebook|     Youtube|\n",
            "|   113|      Organic|     Organic|\n",
            "+------+-------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "first_last_channel_df2.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
