{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIA23YgbXKJd"
      },
      "source": [
        "이를 위해 pyspark과 Py4J 패키지를 설치한다. Py4J 패키지는 파이썬 프로그램이 자바가상머신상의 오브젝트들을 접근할 수 있게 해준다. Local Standalone Spark을 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbT0rpGfVdiq",
        "outputId": "11901df2-fe38-4471-985e-0106df11dbf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.3.1\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=f442d742d67948ded05f6658d3a3d92f2954fcf387f0da9699c3c5d64b560021\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.5.1 py4j==0.10.9.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Iu9l5k_E2ih",
        "outputId": "bac68e19-9910-4aac-e511-7a2c3e26663f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-22 00:37:56--  https://s3-geospatial.s3.us-west-2.amazonaws.com/orders.csv\n",
            "Resolving s3-geospatial.s3.us-west-2.amazonaws.com (s3-geospatial.s3.us-west-2.amazonaws.com)... 52.218.237.201, 3.5.76.178, 3.5.76.198, ...\n",
            "Connecting to s3-geospatial.s3.us-west-2.amazonaws.com (s3-geospatial.s3.us-west-2.amazonaws.com)|52.218.237.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89951 (88K) [text/csv]\n",
            "Saving to: ‘orders.csv.1’\n",
            "\n",
            "orders.csv.1        100%[===================>]  87.84K   272KB/s    in 0.3s    \n",
            "\n",
            "2024-06-22 00:37:57 (272 KB/s) - ‘orders.csv.1’ saved [89951/89951]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-geospatial.s3.us-west-2.amazonaws.com/orders.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_eTGrvXlDw"
      },
      "source": [
        "**Spark Session** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3vm6tgcPXdnR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "your 131072x1 screen size is bogus. expect trouble\n",
            "24/06/22 00:38:33 WARN Utils: Your hostname, LAPTOP-8CK94L0D resolves to a loopback address: 127.0.1.1; using 172.21.9.191 instead (on interface eth0)\n",
            "24/06/22 00:38:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "24/06/22 00:38:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark Hive\") \\\n",
        "    .config(\"spark.jars\", \"/home/sangwon/.local/lib/python3.10/site-packages/pyspark/jars/redshift-jdbc42-2.1.0.14.jar\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbMEqdtjhSaH",
        "outputId": "625a1ecb-bf97-45b1-8fa9-7da258d056b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 368\n",
            "-rw-r--r-- 1 sangwon sangwon 18345 Jun 22 00:38 PySpark_Hive_테이블.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 23991 Jun 22 00:36 PySpark_SQL_사용자별로_처음_채널과_마지막_채널_알아내기.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 24437 Jun 22 00:31 PySpark_SQL_월별_채널별_매출과_방문자_정보.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 16185 Jun 22 00:28 PySpark_SQL_총_매출이_가장_많은_사용자_10명_찾기.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 29758 Jun 21 23:49 PySpark_SQL_JOIN.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 49067 Jun 21 23:29 PySpark_UDF.ipynb\n",
            "drwxr-xr-x 2 sangwon sangwon  4096 Jun 21 23:29 spark-warehouse\n",
            "-rw-r--r-- 1 sangwon sangwon 16979 Jun 20 01:17 PySpark_유닛_테스트.ipynb\n",
            "drwxr-xr-x 2 sangwon sangwon  4096 Jun 20 01:17 unittest\n",
            "-rw-r--r-- 1 sangwon sangwon 89951 Apr 25  2022 orders.csv\n",
            "-rw-r--r-- 1 sangwon sangwon 89951 Apr 25  2022 orders.csv.1\n"
          ]
        }
      ],
      "source": [
        "!ls -tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AT05iUsDEZgO"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Read in data and create a DataFrame\n",
        "df = spark.read.csv(\"orders.csv\", inferSchema=True, header=True, sep ='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwUYSreyhOvf",
        "outputId": "d350fe85-002d-47a3-99fe-c6f8bf8083f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+\n",
            "|    order_id|               items|\n",
            "+------------+--------------------+\n",
            "|860196503764|[{\"name\": \"DAILY ...|\n",
            "|860292645076|[{\"name\": \"DAILY ...|\n",
            "|860320956628|[{\"name\": \"DAILY ...|\n",
            "|860321513684|[{\"name\": \"DAILY ...|\n",
            "|862930665684|[{\"name\": \"DAILY ...|\n",
            "+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL9To7qyu2mL",
        "outputId": "070f7bf2-dfed-41e7-cac2-f5dfb25eef3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/06/22 00:39:05 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
            "24/06/22 00:39:05 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
            "24/06/22 00:39:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
            "24/06/22 00:39:17 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore sangwon@127.0.1.1\n",
            "24/06/22 00:39:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException\n",
            "24/06/22 00:39:17 WARN ObjectStore: Failed to get database test_db, returning NoSuchObjectException\n",
            "24/06/22 00:39:17 WARN ObjectStore: Failed to get database test_db, returning NoSuchObjectException\n",
            "24/06/22 00:39:17 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
            "24/06/22 00:39:17 WARN ObjectStore: Failed to get database test_db, returning NoSuchObjectException\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS TEST_DB\")\n",
        "spark.sql(\"USE TEST_DB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA8GQM-aZj4c",
        "outputId": "375e633c-2df1-4396-ec75-63dd1ae10f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "|  test_db|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SHOW DATABASES\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM26NrabhVPw",
        "outputId": "086d2ea5-24c7-42ee-e310-54ae4b8c4263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 288\n",
            "drwxr-xr-x 3 sangwon sangwon  4096 Jun 22 00:39 spark-warehouse\n",
            "drwxr-xr-x 5 sangwon sangwon  4096 Jun 22 00:39 metastore_db\n",
            "-rw-r--r-- 1 sangwon sangwon   814 Jun 22 00:39 derby.log\n",
            "-rw-r--r-- 1 sangwon sangwon 18345 Jun 22 00:38 PySpark_Hive_테이블.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 23991 Jun 22 00:36 PySpark_SQL_사용자별로_처음_채널과_마지막_채널_알아내기.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 24437 Jun 22 00:31 PySpark_SQL_월별_채널별_매출과_방문자_정보.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 16185 Jun 22 00:28 PySpark_SQL_총_매출이_가장_많은_사용자_10명_찾기.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 29758 Jun 21 23:49 PySpark_SQL_JOIN.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 49067 Jun 21 23:29 PySpark_UDF.ipynb\n",
            "-rw-r--r-- 1 sangwon sangwon 16979 Jun 20 01:17 PySpark_유닛_테스트.ipynb\n",
            "drwxr-xr-x 2 sangwon sangwon  4096 Jun 20 01:17 unittest\n",
            "-rw-r--r-- 1 sangwon sangwon 89951 Apr 25  2022 orders.csv\n"
          ]
        }
      ],
      "source": [
        "!ls -tl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_FzT1klth3St"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/06/22 00:39:38 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
            "24/06/22 00:39:38 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
            "24/06/22 00:39:38 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
            "24/06/22 00:39:38 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
          ]
        }
      ],
      "source": [
        "df.write.saveAsTable(\"TEST_DB.orders\", mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2akh9ojh8px",
        "outputId": "5fd3850b-55b4-41e4-f9c7-aa43a799f260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 24\n",
            "-rw-r--r-- 1 sangwon sangwon     0 Jun 22 00:39 _SUCCESS\n",
            "-rw-r--r-- 1 sangwon sangwon 23051 Jun 22 00:39 part-00000-3b20e2b1-ea93-4360-a241-c86ed89a203e-c000.snappy.parquet\n"
          ]
        }
      ],
      "source": [
        "!ls -tl spark-warehouse/test_db.db/orders/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk_bSxqkFC7Y",
        "outputId": "277a8d1f-8ca7-48d7-a9ce-ce5c4ffa5a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+\n",
            "|    order_id|               items|\n",
            "+------------+--------------------+\n",
            "|860196503764|[{\"name\": \"DAILY ...|\n",
            "|860292645076|[{\"name\": \"DAILY ...|\n",
            "|860320956628|[{\"name\": \"DAILY ...|\n",
            "|860321513684|[{\"name\": \"DAILY ...|\n",
            "|862930665684|[{\"name\": \"DAILY ...|\n",
            "+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT * FROM TEST_DB.orders\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WBmG-TNFIu7",
        "outputId": "cb23c8d3-a1b4-4049-8d70-95582004a8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+\n",
            "|    order_id|               items|\n",
            "+------------+--------------------+\n",
            "|860196503764|[{\"name\": \"DAILY ...|\n",
            "|860292645076|[{\"name\": \"DAILY ...|\n",
            "|860320956628|[{\"name\": \"DAILY ...|\n",
            "|860321513684|[{\"name\": \"DAILY ...|\n",
            "|862930665684|[{\"name\": \"DAILY ...|\n",
            "+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.table(\"TEST_DB.orders\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULtPpbXgF27m",
        "outputId": "bd159ba9-1590-4632-8ac5-7d4bf6501c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 28\n",
            "drwxr-xr-x 2 sangwon sangwon 4096 Jun 22 00:39 seg0\n",
            "-rw-r--r-- 1 sangwon sangwon  952 Jun 22 00:39 service.properties\n",
            "-rw-r--r-- 1 sangwon sangwon  608 Jun 22 00:39 README_DO_NOT_TOUCH_FILES.txt\n",
            "drwxr-xr-x 2 sangwon sangwon 4096 Jun 22 00:39 log\n",
            "-rw-r--r-- 1 sangwon sangwon   38 Jun 22 00:39 db.lck\n",
            "-rw-r--r-- 1 sangwon sangwon    4 Jun 22 00:39 dbex.lck\n",
            "drwxr-xr-x 2 sangwon sangwon 4096 Jun 22 00:39 tmp\n"
          ]
        }
      ],
      "source": [
        "!ls -tl metastore_db/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFE9zkakGA55",
        "outputId": "fed66300-78d5-44cb-8317-af7830196cb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Table(name='orders', catalog='spark_catalog', namespace=['test_db'], description=None, tableType='MANAGED', isTemporary=False)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYqTUySXif_H",
        "outputId": "7a4d2069-cc0f-407e-e7d1-77df45e016cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "    DROP TABLE IF EXISTS TEST_DB.orders_count;\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zy1yzp9jUmQ",
        "outputId": "297f740c-2e9c-4aae-cad8-c77ea90e2138"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/06/22 00:40:32 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n",
            "24/06/22 00:40:33 WARN HiveMetaStore: Location: file:/home/sangwon/devcourse/spark/examples/pyspark_example/chapter3/spark-warehouse/test_db.db/orders_count specified for non-external table:orders_count\n",
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.sql(\"\"\"\n",
        "    CREATE TABLE TEST_DB.orders_count AS \n",
        "    SELECT order_id, COUNT(1) as count \n",
        "    FROM TEST_DB.orders\n",
        "    GROUP BY 1\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVSEuePEiyYW",
        "outputId": "a267b7bf-4f2e-42de-b0c6-da0646a9a4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Table(name='orders', catalog='spark_catalog', namespace=['test_db'], description=None, tableType='MANAGED', isTemporary=False),\n",
              " Table(name='orders_count', catalog='spark_catalog', namespace=['test_db'], description=None, tableType='MANAGED', isTemporary=False)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark.catalog.listTables()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgplGelhi0hq",
        "outputId": "a2a3ed5f-e2ee-4893-f1ef-4644164c2bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 8\n",
            "drwxr-xr-x 2 sangwon sangwon 4096 Jun 22 00:40 orders_count\n",
            "drwxr-xr-x 2 sangwon sangwon 4096 Jun 22 00:39 orders\n"
          ]
        }
      ],
      "source": [
        "!ls -tl spark-warehouse/test_db.db/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGcE_5LXi4zj",
        "outputId": "7638fb4e-fae2-48da-e866-77b8ab3531d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+\n",
            "|     order_id|count|\n",
            "+-------------+-----+\n",
            "|1209310019796|    1|\n",
            "|1253925257428|    1|\n",
            "|1314797846740|    1|\n",
            "|1370637402324|    1|\n",
            "|1967690285268|    1|\n",
            "|1971226443988|    1|\n",
            "|2106987970772|    1|\n",
            "|2135281533140|    1|\n",
            "|1271771070676|    1|\n",
            "|1713331765460|    1|\n",
            "+-------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT * FROM test_db.orders_count LIMIT 10\").show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LoCk7SgRrFuP",
        "QkvG7CGo1BgF",
        "YV16sPAT04lt",
        "cdANBnd70u-E",
        "ziIgaC_cXx8S",
        "1bbYGM8MX3zO",
        "9nO5mhnwPozH",
        "uBXdq3jqPwur"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
